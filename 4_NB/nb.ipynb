{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('tensorflow-gpu': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5683effc006db3b1c4689a623e2360bf9675d37d543b724f66752a231dd1539b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用sklearn中的高斯贝叶斯\n",
    "# 导包\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据集\n",
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "index",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\ProgramData\\Miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'index'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-826af60f8c3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: index"
     ]
    }
   ],
   "source": [
    "print(type(iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(iris.data)\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#切分数据集\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(iris.data, iris.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "112 38\n"
     ]
    }
   ],
   "source": [
    "print(len(Xtrain), len(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "#建模\n",
    "clf = GaussianNB()\n",
    "clf.fit(Xtrain, ytrain)\n",
    "pred = clf.predict(Xtest)\n",
    "#测试准确率\n",
    "accuracy_score(ytest, clf.predict(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手写朴素贝叶斯分类器\n",
    "# 导包\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RangeIndex(start=0, stop=150, step=1)\n"
     ]
    }
   ],
   "source": [
    "dataSet = pd.read_csv('../data//4_nb//iris.txt',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "     0    1    2    3            4\n0  5.1  3.5  1.4  0.2  Iris-setosa\n1  4.9  3.0  1.4  0.2  Iris-setosa\n2  4.7  3.2  1.3  0.2  Iris-setosa\n3  4.6  3.1  1.5  0.2  Iris-setosa\n4  5.0  3.6  1.4  0.2  Iris-setosa",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(dataSet[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randSplit(dataSet, rate):\n",
    "    l = list(dataSet.index) #提取出索引\n",
    "    random.shuffle(l) #随机打乱索引\n",
    "    dataSet.index = l #将打乱后的索引重新赋值给原数据集\n",
    "    n = dataSet.shape[0] #总行数\n",
    "    m = int(n * rate) #训练集的数量\n",
    "    train = dataSet.loc[range(m), :] #提取前m个记录作为训练集\n",
    "    test = dataSet.loc[range(m, n), :] #剩下的作为测试集\n",
    "    dataSet.index = range(dataSet.shape[0]) #更新原数据集的索引\n",
    "    test.index = range(test.shape[0]) #更新测试集的索引\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "     0    1    2    3                4\n0  5.5  2.4  3.8  1.1  Iris-versicolor\n1  4.7  3.2  1.3  0.2      Iris-setosa\n2  6.7  3.0  5.2  2.3   Iris-virginica\n3  5.6  2.5  3.9  1.1  Iris-versicolor\n4  6.7  3.1  5.6  2.4   Iris-virginica",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.5</td>\n      <td>2.4</td>\n      <td>3.8</td>\n      <td>1.1</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.6</td>\n      <td>2.5</td>\n      <td>3.9</td>\n      <td>1.1</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.7</td>\n      <td>3.1</td>\n      <td>5.6</td>\n      <td>2.4</td>\n      <td>Iris-virginica</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "     0    1    2    3                4\n0  5.8  2.8  5.1  2.4   Iris-virginica\n1  5.1  3.7  1.5  0.4      Iris-setosa\n2  5.4  3.0  4.5  1.5  Iris-versicolor\n3  5.0  3.4  1.5  0.2      Iris-setosa\n4  6.5  3.0  5.2  2.0   Iris-virginica",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.8</td>\n      <td>2.8</td>\n      <td>5.1</td>\n      <td>2.4</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.1</td>\n      <td>3.7</td>\n      <td>1.5</td>\n      <td>0.4</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.4</td>\n      <td>3.0</td>\n      <td>4.5</td>\n      <td>1.5</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>3.4</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n      <td>Iris-virginica</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "train, test = randSplit(dataSet, 0.8)\n",
    "display(train[:5])\n",
    "display(test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnb_classify(train,test):\n",
    "    labels = train.iloc[:,-1].value_counts().index #提取训练集的标签种类\n",
    "    mean =[] #存放每个类别的均值\n",
    "    std =[] #存放每个类别的方差\n",
    "    pred = [] #存放测试集的预测结果\n",
    "    for i in labels:\n",
    "        item = train.loc[train.iloc[:,-1]==i,:] #分别提取出每一种类别\n",
    "        m = item.iloc[:,:-1].mean() #当前类别的平均值\n",
    "        # s = np.sum((item.iloc[:,:-1]-m)**2)/(item.shape[0]) #\n",
    "        s = item.iloc[:, :-1].std() ** 2\n",
    "        mean.append(m) #将当前类别的平均值追加至列表\n",
    "        std.append(s) #将当前类别的方差追加至列表\n",
    "    means = pd.DataFrame(mean,index=labels) #变成DF格式，索引为类标签\n",
    "    stds = pd.DataFrame(std,index=labels) #变成DF格式，索引为类标签\n",
    "    for j in range(test.shape[0]):\n",
    "        iset = test.iloc[j,:-1].tolist() #当前测试实例\n",
    "        iprob = np.exp(-1*(iset-means)**2/(stds*2))/(np.sqrt(2*np.pi*stds)) #正态分布公式\n",
    "        # display(iset)\n",
    "        # display(iprob)\n",
    "        prob = 1 #初始化当前实例总概率\n",
    "        for k in range(test.shape[1]-1): #遍历每个特征\n",
    "            prob *= iprob[k] #特征概率之积即为当前实例概率\n",
    "            # display(prob)\n",
    "            # display(np.argmax(prob.values))\n",
    "            cla = prob.index[np.argmax(prob.values)] #返回最大概率的类别\n",
    "        pred.append(cla)\n",
    "    # test['predict']=result\n",
    "    acc = (test.iloc[:,-1]==pred).mean() #计算预测准确率\n",
    "    print(f'模型预测准确率为{acc}')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "模型预测准确率为0.9333333333333333\n",
      "模型预测准确率为1.0\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9333333333333333\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9333333333333333\n",
      "模型预测准确率为0.9333333333333333\n",
      "模型预测准确率为1.0\n",
      "模型预测准确率为0.9333333333333333\n",
      "模型预测准确率为0.8666666666666667\n",
      "模型预测准确率为0.8666666666666667\n",
      "模型预测准确率为0.9\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9333333333333333\n",
      "模型预测准确率为0.9\n",
      "模型预测准确率为0.9666666666666667\n",
      "模型预测准确率为0.9\n",
      "模型预测准确率为0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train,test= randSplit(dataSet, 0.8)\n",
    "    gnb_classify(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用朴素贝叶斯进行文档分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    dataSet=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "             ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "             ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "             ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "             ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "             ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']] #切分好的词条\n",
    "    classVec = [0,1,0,1,0,1] #类别标签向量，1代表侮辱性词汇，0代表非侮辱性词汇\n",
    "    return dataSet,classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet,classVec = loadDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "[0, 1, 0, 1, 0, 1]"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(dataSet)\n",
    "display(classVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVocabList(dataSet):\n",
    "    vocabSet = set() #创建一个空的集合\n",
    "    for doc in dataSet: #遍历dataSet中的每一条言论\n",
    "        vocabSet = vocabSet | set(doc) #取并集\n",
    "        vocabList = list(vocabSet)\n",
    "    return vocabList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['stupid', 'love', 'stop', 'buying', 'has', 'I', 'please', 'my', 'cute', 'quit', 'mr', 'dog', 'licks', 'worthless', 'maybe', 'so', 'posting', 'how', 'him', 'steak', 'take', 'food', 'ate', 'problems', 'is', 'help', 'flea', 'park', 'dalmation', 'to', 'not', 'garbage']\n"
     ]
    }
   ],
   "source": [
    "vocabList = createVocabList(dataSet)\n",
    "print(vocabList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    returnVec = [0] * len(vocabList) #创建一个其中所含元素都为0的向量\n",
    "    for word in inputSet: #遍历每个词条\n",
    "        if word in vocabList: #如果词条存在于词汇表中，则变为1\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else:\n",
    "            print(f\" {word} is not in my Vocabulary!\" )\n",
    "    return returnVec #返回文档向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainMat(dataSet):\n",
    "    trainMat = [] #初始化向量列表\n",
    "    vocabList = createVocabList(dataSet) #生成词汇表\n",
    "    for inputSet in dataSet: #遍历样本词条中的每一条样本\n",
    "        returnVec=setOfWords2Vec(vocabList, inputSet) #将当前词条向量化\n",
    "        trainMat.append(returnVec) #追加到向量列表中\n",
    "    return trainMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6\n[0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "trainMat = get_trainMat(dataSet)\n",
    "n = len(trainMat) #计算训练的文档数目\n",
    "m = len(trainMat[0]) #计算每篇文档的词条数\n",
    "# print(trainMat[3])\n",
    "# print(sum(trainMat[3]))\n",
    "print(n)\n",
    "print(trainMat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle 旧金山犯罪预测\n",
    "# 导包\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data//4_nb//Kaggle/train.csv',parse_dates = ['Dates'])\n",
    "test = pd.read_csv('../data//4_nb//Kaggle/test.csv',parse_dates = ['Dates'],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                Dates        Category                      Descript  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "2 2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "3 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "4 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
       "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.425892  37.774599  \n",
       "1 -122.425892  37.774599  \n",
       "2 -122.424363  37.800414  \n",
       "3 -122.426995  37.800873  \n",
       "4 -122.438738  37.771541  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dates</th>\n      <th>Category</th>\n      <th>Descript</th>\n      <th>DayOfWeek</th>\n      <th>PdDistrict</th>\n      <th>Resolution</th>\n      <th>Address</th>\n      <th>X</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-05-13 23:53:00</td>\n      <td>WARRANTS</td>\n      <td>WARRANT ARREST</td>\n      <td>Wednesday</td>\n      <td>NORTHERN</td>\n      <td>ARREST, BOOKED</td>\n      <td>OAK ST / LAGUNA ST</td>\n      <td>-122.425892</td>\n      <td>37.774599</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-05-13 23:53:00</td>\n      <td>OTHER OFFENSES</td>\n      <td>TRAFFIC VIOLATION ARREST</td>\n      <td>Wednesday</td>\n      <td>NORTHERN</td>\n      <td>ARREST, BOOKED</td>\n      <td>OAK ST / LAGUNA ST</td>\n      <td>-122.425892</td>\n      <td>37.774599</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-05-13 23:33:00</td>\n      <td>OTHER OFFENSES</td>\n      <td>TRAFFIC VIOLATION ARREST</td>\n      <td>Wednesday</td>\n      <td>NORTHERN</td>\n      <td>ARREST, BOOKED</td>\n      <td>VANNESS AV / GREENWICH ST</td>\n      <td>-122.424363</td>\n      <td>37.800414</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-05-13 23:30:00</td>\n      <td>LARCENY/THEFT</td>\n      <td>GRAND THEFT FROM LOCKED AUTO</td>\n      <td>Wednesday</td>\n      <td>NORTHERN</td>\n      <td>NONE</td>\n      <td>1500 Block of LOMBARD ST</td>\n      <td>-122.426995</td>\n      <td>37.800873</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-05-13 23:30:00</td>\n      <td>LARCENY/THEFT</td>\n      <td>GRAND THEFT FROM LOCKED AUTO</td>\n      <td>Wednesday</td>\n      <td>PARK</td>\n      <td>NONE</td>\n      <td>100 Block of BRODERICK ST</td>\n      <td>-122.438738</td>\n      <td>37.771541</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 Dates DayOfWeek PdDistrict                   Address  \\\n",
       "Id                                                                      \n",
       "0  2015-05-10 23:59:00    Sunday    BAYVIEW   2000 Block of THOMAS AV   \n",
       "1  2015-05-10 23:51:00    Sunday    BAYVIEW        3RD ST / REVERE AV   \n",
       "2  2015-05-10 23:50:00    Sunday   NORTHERN    2000 Block of GOUGH ST   \n",
       "3  2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "4  2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "\n",
       "             X          Y  \n",
       "Id                         \n",
       "0  -122.399588  37.735051  \n",
       "1  -122.391523  37.732432  \n",
       "2  -122.426002  37.792212  \n",
       "3  -122.437394  37.721412  \n",
       "4  -122.437394  37.721412  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dates</th>\n      <th>DayOfWeek</th>\n      <th>PdDistrict</th>\n      <th>Address</th>\n      <th>X</th>\n      <th>Y</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-05-10 23:59:00</td>\n      <td>Sunday</td>\n      <td>BAYVIEW</td>\n      <td>2000 Block of THOMAS AV</td>\n      <td>-122.399588</td>\n      <td>37.735051</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-05-10 23:51:00</td>\n      <td>Sunday</td>\n      <td>BAYVIEW</td>\n      <td>3RD ST / REVERE AV</td>\n      <td>-122.391523</td>\n      <td>37.732432</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-05-10 23:50:00</td>\n      <td>Sunday</td>\n      <td>NORTHERN</td>\n      <td>2000 Block of GOUGH ST</td>\n      <td>-122.426002</td>\n      <td>37.792212</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-05-10 23:45:00</td>\n      <td>Sunday</td>\n      <td>INGLESIDE</td>\n      <td>4700 Block of MISSION ST</td>\n      <td>-122.437394</td>\n      <td>37.721412</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-05-10 23:45:00</td>\n      <td>Sunday</td>\n      <td>INGLESIDE</td>\n      <td>4700 Block of MISSION ST</td>\n      <td>-122.437394</td>\n      <td>37.721412</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对犯罪类别:Category; 用LabelEncoder进行编号\n",
    "leCrime = LabelEncoder()\n",
    "crime = leCrime.fit_transform(train.Category) #39种犯罪类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = pd.get_dummies(train.DayOfWeek)\n",
    "district = pd.get_dummies(train.PdDistrict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(878049,)"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "hour = train.Dates.dt.hour\n",
    "hour = pd.get_dummies(hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "23228"
      ]
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "source": [
    "# address = pd.get_dummies(train.Address)\n",
    "len(train.loc[:, 'Address'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(878049, 9) (884262, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Dates  Friday  Monday  Saturday  Sunday  Thursday  Tuesday  Wednesday  \\\n",
       "0     23       0       0         0       0         0        0          1   \n",
       "1     23       0       0         0       0         0        0          1   \n",
       "2     23       0       0         0       0         0        0          1   \n",
       "3     23       0       0         0       0         0        0          1   \n",
       "4     23       0       0         0       0         0        0          1   \n",
       "\n",
       "   BAYVIEW  CENTRAL  INGLESIDE  MISSION  NORTHERN  PARK  RICHMOND  SOUTHERN  \\\n",
       "0        0        0          0        0         1     0         0         0   \n",
       "1        0        0          0        0         1     0         0         0   \n",
       "2        0        0          0        0         1     0         0         0   \n",
       "3        0        0          0        0         1     0         0         0   \n",
       "4        0        0          0        0         0     1         0         0   \n",
       "\n",
       "   TARAVAL  TENDERLOIN  crime  \n",
       "0        0           0     37  \n",
       "1        0           0     21  \n",
       "2        0           0     21  \n",
       "3        0           0     16  \n",
       "4        0           0     16  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dates</th>\n      <th>Friday</th>\n      <th>Monday</th>\n      <th>Saturday</th>\n      <th>Sunday</th>\n      <th>Thursday</th>\n      <th>Tuesday</th>\n      <th>Wednesday</th>\n      <th>BAYVIEW</th>\n      <th>CENTRAL</th>\n      <th>INGLESIDE</th>\n      <th>MISSION</th>\n      <th>NORTHERN</th>\n      <th>PARK</th>\n      <th>RICHMOND</th>\n      <th>SOUTHERN</th>\n      <th>TARAVAL</th>\n      <th>TENDERLOIN</th>\n      <th>crime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "#组合特征形成训练集\n",
    "trainData = pd.concat([hour, days, district], axis = 1) #将特征进行左右拼接\n",
    "trainData['crime'] = crime #追加标签列\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    0  1  2  3  4  5  6  7  8  9  ...  BAYVIEW  CENTRAL  INGLESIDE  MISSION  \\\n",
       "Id                                ...                                         \n",
       "0   0  0  0  0  0  0  0  0  0  0  ...        1        0          0        0   \n",
       "1   0  0  0  0  0  0  0  0  0  0  ...        1        0          0        0   \n",
       "2   0  0  0  0  0  0  0  0  0  0  ...        0        0          0        0   \n",
       "3   0  0  0  0  0  0  0  0  0  0  ...        0        0          1        0   \n",
       "4   0  0  0  0  0  0  0  0  0  0  ...        0        0          1        0   \n",
       "\n",
       "    NORTHERN  PARK  RICHMOND  SOUTHERN  TARAVAL  TENDERLOIN  \n",
       "Id                                                           \n",
       "0          0     0         0         0        0           0  \n",
       "1          0     0         0         0        0           0  \n",
       "2          1     0         0         0        0           0  \n",
       "3          0     0         0         0        0           0  \n",
       "4          0     0         0         0        0           0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>BAYVIEW</th>\n      <th>CENTRAL</th>\n      <th>INGLESIDE</th>\n      <th>MISSION</th>\n      <th>NORTHERN</th>\n      <th>PARK</th>\n      <th>RICHMOND</th>\n      <th>SOUTHERN</th>\n      <th>TARAVAL</th>\n      <th>TENDERLOIN</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "#得到测试集\n",
    "days = pd.get_dummies(test.DayOfWeek)\n",
    "district = pd.get_dummies(test.PdDistrict)\n",
    "hour = test.Dates.dt.hour\n",
    "hour = pd.get_dummies(hour)\n",
    "testData = pd.concat([hour, days, district], axis=1)\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#切分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainData.iloc[:,:-1],\n",
    "                                                    trainData.iloc[:,-1],\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.6100908873558524\n"
     ]
    }
   ],
   "source": [
    "#训练模型\n",
    "BNB = BernoulliNB()\n",
    "BNB.fit(X_train, y_train)\n",
    "\n",
    "#计算损失函数\n",
    "propa = BNB.predict_proba(X_test)\n",
    "logLoss=log_loss(y_test, propa)\n",
    "print(logLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.606643454595278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#多项式分布朴素贝叶斯\n",
    "mnb = MultinomialNB() #获取模型\n",
    "mnb.fit(X_train,y_train) #训练模型\n",
    "#计算损失函数\n",
    "propa_mnb = mnb.predict_proba(X_test)\n",
    "logLoss_mnb = log_loss(y_test, propa_mnb)\n",
    "print(logLoss_mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.00121228 0.08642866 0.0004683  ... 0.04999086 0.0266955  0.00556435]\n [0.00537714 0.12338333 0.00021427 ... 0.08795306 0.04129813 0.02089897]\n [0.00128586 0.09454069 0.00027493 ... 0.05069216 0.02857351 0.00541528]\n ...\n [0.00148915 0.0718627  0.00060966 ... 0.05708828 0.04723701 0.00695939]\n [0.00148915 0.0718627  0.00060966 ... 0.05708828 0.04723701 0.00695939]\n [0.00241171 0.06528889 0.00057282 ... 0.0996303  0.01954773 0.00731881]]\n[[0.00121268 0.08633204 0.00047122 ... 0.05132755 0.02855861 0.00590305]\n [0.00347467 0.11367749 0.00017568 ... 0.09482439 0.04262954 0.01940047]\n [0.00138328 0.09520998 0.00032233 ... 0.05015216 0.03041484 0.0057491 ]\n ...\n [0.00209125 0.07990231 0.00099565 ... 0.04853272 0.04802356 0.0071193 ]\n [0.00203775 0.07943936 0.00095858 ... 0.04916298 0.04799486 0.00713349]\n [0.00260664 0.06858678 0.00069954 ... 0.09079156 0.02066119 0.00742769]]\n"
     ]
    }
   ],
   "source": [
    "print(propa)\n",
    "print(propa_mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}